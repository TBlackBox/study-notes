https://www.cnblogs.com/tong-yuan/p/all.html

前面两节，我们一起学习了关于跳表的理论知识，并手写了两种完全不同的实现，我们放一张图来简单地回顾一下：

![15](../sources\datastructure\1648938-20200917221029345-1242929879.jpg)

实现跳表的关键之处是在有序链表的基础上加上各层索引，通过这些索引可以做到O(log n)的时间复杂度快速地插入、删除、查找元素。

说起跳表，我们就不得不提另一种非常经典的数据结构——红黑树，红黑树相对于跳表来说，虽然时间复杂度都是O(log n)，但是红黑树的使用场景相对更广泛一些，在早期的Linux内核中就一直存在红黑树的实现，也运用在了更高效的多路复用器Epoll中。

所以，红黑树是每一个程序员不得不会的知识点，甚至有些变态的面试官，还会让你手写红黑树的一部分实现，比如左旋、右旋、插入平衡的过程、删除平衡的过程，这些内容非常复杂，靠死记硬背往往很难彻底掌握。

彤哥也是一直在寻找一种红黑树的记忆法，总算让我找到了那么一种还算不错的方式，从红黑树的起源出发，理解红黑树的本质，再从本质出发，彻底掌握不用死记硬背的方法，最后再把它手写出来。

从本节开始，我也将把这种方法传递给你，因此，红黑树的部分，我会分成三个小节来讲解：

- 从红黑树的起源，到红黑树的本质
- 从红黑树的本质，找到不用死记硬背的方法
- 不靠死记硬背，手写红黑树

好了，下面我们就进入第一小节。

# 红黑树的起源

## 二叉树

说起树，我们不得不说最有名的树，那就是二叉树，什么是二叉树呢？

**二叉树（binary tree）**，是指树中的每个节点最多只有两个子节点的树。

![1](../sources\datastructure\1648938-20200917221029940-1224265774.jpg)

当然，二叉树本身似乎没什么用，我们平时说的二叉树基本上都是指二叉查找树，或者叫有序二叉树、二叉搜索树、二叉排序树。

## 二叉查找树

**二叉查找树（BST，binary search tree）**，就是在二叉树的基础上增加有序性，这个有序性一般是指自然顺序，有了有序性，我们就可以使用二叉树来快速的查找、删除、插入元素了。

![2](../sources\datastructure\1648938-20200917221030432-711590938.jpg)

比如，上面这颗二叉查找树，查找元素的平均时间复杂度为O(log n)。

但是，二叉查找树有个非常严重的问题，试想，还是这三个元素，如果按照A、B、C的顺序插入元素会怎样？

![3](../sources\datastructure\1648938-20200917221030937-1391530984.jpg)

这是啥？单链表？没错，当按照元素的自然顺序插入元素的时候，二叉查找树就退化成单链表了，单链表的插入、删除、查找元素的时间复杂度是多少？O(n)。

所以，在极限情况下，二叉查找树的时间复杂度是非常差的。

既然，插入元素后有可能导致二叉查找树的性能变差，那么，我们是否可以增加一些手段，让插入元素后的二叉查找树依然性能良好呢？

答案是肯定的，这种手段就叫做`平衡`，这种可以自平衡的树就叫做平衡树。

## 平衡树

**平衡树（self-balancing or height-balanced binary search tree）**，是指插入、删除元素后可以自平衡的二叉查找树，使得它的时间复杂度可以一直渐近于O(log n)。

比如，上面那颗树，按A、B、C插入元素后，做一次旋转操作，就可以再次变成查找时间复杂度为O(log n)的树。

![4](../sources\datastructure\1648938-20200917221031475-132666712.jpg)

但是，平衡树一直只是一个概念，直到1962年才由两个苏联人发明了第一种平衡树——AVL树。

> 严格来说，平衡树是指可以自平衡的二叉查找树，三个关键词：自平衡、二叉、查找（有序）。

## AVL树

AVL树（由发明者**A**delson-**V**elsky 和 **L**andis 的首字母缩写命名），是指任意节点的两个子树的高度差不超过1的平衡树。

![5](../sources\datastructure\1648938-20200917221032043-1804791188.jpg)

比如，上面这颗树，就是一颗AVL树，不信你可以数数看，是不是每个节点的两个子树的高度差都不超过1。

是不是很难发现它真的是一颗AVL树，没错，这是AVL树的第一个缺点，不够直观，特别是节点个数多的时候。

第二个缺点，就是插入、删除元素的时候自平衡的过程非常复杂，比如，上面这颗树插入一个节点`T`：

![6](../sources\datastructure\1648938-20200917221032623-461173927.jpg)

我们从T往上找，它的父节点U，U的两颗子树的高度差为1，满足AVL树的规则，再往上，S的两颗子树的高度差为1，也满足规则，再往上，V的两颗子树的高度差为2，不满足规则，此时，需要一个自平衡的过程，该如何自平衡呢？

我下面给出图示，你可以试着理解一下：

![7](../sources\datastructure\1648938-20200917221033218-651065667.jpg)

红色节点表示旋转的轴。

经过两次旋转，让这颗树再次变成了AVL树，而且这只是其中一种插入场景，真实的情况还要根据插入的位置的不同做不同的旋转，你可以多插入几个节点自己尝试平衡一下。

同样地，AVL树的代码也不是那么好实现的，反正，到目前为止，彤哥是没搞懂AVL树的各种规则。

基于这些缺点，所以，后来又发展出来了各种各样的神奇的平衡树。

## 2-3树

**2-3树**，是指每个具有子节点的节点（内部节点，internal node）要么有两个子节点和一个数据元素，要么有三个子节点和两个数据元素的自平衡的树，它的所有叶子节点都具有相同的高度。

简单点讲，2-3树的非叶子节点都具有两个分叉或者三个分叉，所以，称作2叉-3叉树更容易理解。

另外一种说法，具有两个子节点和一个数据元素的节点又称作2节点，具有三个子节点和两个数据元素的节点又称作3节点，所以，整颗树叫做2-3树。

![8](../sources\datastructure\1648938-20200917221033869-414059503.jpg)

2-3树，插入元素后自平衡的过程相对于AVL树就要简单得多了，比如，上面这颗树，再插入一个元素K，它会先找到`I J`这个节点，插入元素K，形成临时节点`I J K`，不符合2-3树的规则，所以分裂，`J`往上移，`F H`这个节点变成了`F H J`了，也不符合2-3树的规则，继续上移`H`，根节点变为`D H`，同时，上移的过程中，子节点也要相应的分裂，过程大致如下：

![9](../sources\datastructure\1648938-20200917221034443-1207439204.jpg)

> 画图辛苦了，关注一波：彤哥读源码。

可以看到，上面自平衡的过程中，出现了一种节点，它具有四个子节点和三个数据元素，这个节点可以称作4节点，如果把4节点当作是可以允许存在的，那么，就出现了另一种树：2-3-4树。

## 2-3-4树

**2-3-4树**，它的每个非叶子节点，要么是2节点，要么是3节点，要么是4节点，且可以自平衡，所以称作2-3-4树。

2节点、3节点、4节点的定义在上面已经提及，我们再重申一下：

2节点：包含两个子节点和一个数据元素；

3节点：包含三个子节点和两个数据元素；

4节点：包含四个子节点和三个数据元素；

![10](../sources\datastructure\1648938-20200917221035073-1204612399.jpg)

当然，2-3-4树插入元素的过程也很好理解，比如，上面这颗树，插入元素M，找到`K L`这个节点，插入即可，形成4节点，满足规则，不需要自平衡：

![11](../sources\datastructure\1648938-20200917221035628-1851432460.jpg)

再插入元素N呢？过程与2-3树一样，向上分裂即可，此时，中间节点有两个，取任意一个上移都是可以的，我们这里以左中节点上移为例，大致过程如下：

![12](../sources\datastructure\1648938-20200917221036174-795716654.jpg)

是不是挺简单的，至少比AVL树那种左旋右旋简单得多。

同样地，在2-3-4树自平衡的过程中出现了临时的5节点，所以，如果允许5节点的存在呢？

嗯，2-3-4-5树由此诞生！

同样地，还有2-3-4-5-6树、2-3-4-5-6-7树……子子孙孙，无穷尽也~

所以，有人就把这一类树归纳为一个新的名字：B树。

## B树

**B树**，表示的是一类树，它允许一个节点可以有多于两个子节点，同时，也是自平衡的，叶子节点的高度都是相同的。

所以，为了更好地区分一颗B树到底属于哪一类树，我们给它一个新的属性：度（Degree）。

具有度为3的B树，表示一个节点最多有三个子节点，也就是2-3树的定义。

具有度为4的B树，表示一个节点最多有四个子节点，也就是2-3-4树的定义。

![13](../sources\datastructure\1648938-20200917221036809-216076303.jpg)

B树，一个节点可以存储多个元素，有利于缓存磁盘数据，整体的时间复杂度趋向于O(log n)，原理也比较简单，所以，经常用于数据库的索引，包括早期的mysql也是使用B树来作为索引的。

但是，B树有个大缺陷，比如，我要按范围查找元素，以上面的2-3-4树为例，查找大于B且小于K的所有元素，该怎么实现呢？

很难，几乎无解，所以，后面又出现替代B树的方案：B+树。

当然了，B+树不是本节的重点，本节的重点是红黑树。

纳尼，红黑树在哪里？写了3000多字了，还没见到红黑树的影子，我尬了~

来了来了，有意思的红黑树来了~~

## 红黑树

先上一张图，请仔细体会：

![14](../sources\datastructure\1648938-20200917221037398-1979647049.jpg)

看明白了没有？红黑树是啥？红黑树就是2-3-4树！！！

OK，本节到此结束。

# 后记

本节，我们一起从二叉树出发，一路经过二叉查找树、平衡树、AVL树、2-3树、2-3-4树、B树，最后终于得出了红黑树的本质，红黑树的本质就是一颗2-3-4树，换了个皮肤而已。

那么，为什么要再造一个红黑树呢？直接用2-3-4树它不香么？

我们下一节解答，同时，下一节，我们将从红黑树的本质出发，彻底理解红黑树插入、删除、查找、左旋、右旋的全过程，再也不用死记硬背了，还不来关注我^^





# 前言

早上好，我是彤哥。

上一节，我们一起从二叉树、二叉查找树、平衡树、AVL树、2-3树、2-3-4树、B树，一路讲到红黑树，最后得出红黑树的本质：红黑树就是2-3-4树，请看下图：

![14](../sources\datastructure\1648938-20201012074056717-376018948.jpg)

我们知道2-3-4的插入、删除、查找元素的原理是相当简单的，那么，我们是不是可以利用2-3-4树来记忆红黑树呢？

答案是肯定的，本节，我们就来看看如何利用2-3-4树来快速掌握红黑树，再也不用死记硬背了~~

好了，让我们进入今天的学习吧。

# 再忆2-3-4树

我们给出一张图简单地回顾一下上一节关于2-3-4树插入元素N的过程：

![12](../sources\datastructure\1648938-20201012074057429-1815659933.jpg)

> 关注公主号彤哥读源码，查看上一节的内容。

# 左倾红黑树、右倾红黑树、AA树

在正式讲解红黑树之前呢，彤哥先来给大家普及几个有意思的概念，分别是左倾红黑树、右倾红黑树、AA树。

```
图片太小？试试横屏！
```

![1](../sources\datastructure\1648938-20201012074058466-1524364404.jpg)

请看上图，其实按照红黑树的概念，上面3颗树都是红黑树，而且元素也是一模一样，可以说是同一颗红黑树的不同变种。

> 细心的同学会发现①和②是同一颗2-3-4树演化而来，③是这颗2-3-4树缩小成2-3树的样子。

那么，到底什么是红黑树呢？

红黑树是每个节点都带有颜色属性的二叉查找树，颜色或红色或黑色。

首先，红黑树是一颗二叉查找树，另外，它还必须满足以下五点要求：

1. 节点是红色或黑色；
2. 根节点是黑色；
3. 所有叶子节点是黑色；（叶子节点是NULL节点）
4. 每个红色节点的两个子节点都是黑色；（从根节点到每个叶子节点的路径上不能有两个连续的红节点）
5. 从任何一个节点到每个叶子节点的所有路径都包含相同数目的黑色节点；

大家不用记这个概念哈，因为确实很难记得住哈，下面彤哥会教大家更简单的方法。

所以，你看上面三个图是不是都是红黑树呢？

并不是啊，因为叶子节点有的是红色的呀。

其实，它们都是红黑树，让我把叶子节点补齐：

![2](../sources\datastructure\1648938-20201012074058910-174221356.jpg)

你再仔细看看，是不是满足上面五条规则了？！

所以，你看，随便画一颗树，它都可能满足红黑树的定义，因此，为了方便记忆，我们将红黑树分成这么几种类型：左倾红黑树、右倾红黑树、AA树。

**左倾红黑树（LLRB，Left-Learning Red-Black Tree）**，一个节点如果有红色子节点，那么，它的红色子节点是向左倾斜的。

怎么理解呢？

我们还是把上面的null节点干掉哈，叶子节点都是null节点，那是经典红黑树的讲法，到彤哥这里，完全不存在这种要求。

我们来看，一个节点要么有一个子节点，要么有两个子节点，对吧。

如果这个节点有红色的子节点呢，也是一个或者两个，如果只有一个红色子节点的话，那么，这个子节点只能在左边，如果是有两个红色子节点，那就不用管。

所以，整颗红黑树中，如果存在红色节点，那么只能是下面这两种形态：

![3](../sources\datastructure\1648938-20201012074059414-1027161624.jpg)

同理，**右倾红黑树（RLRB，Right-Learning Red-Black Tree）**，也是一样的道理，即红色子节点向右倾斜，它的红色子节点只能是下面这两种形态：

![4](../sources\datastructure\1648938-20201012074059806-1197523327.jpg)

好了，左倾和右倾红黑树都还算比较正常的形态，还有一种变态的红黑树，叫作**AA树（AA Tree）**。

当然，这里的AA不是吃饭的时候大家各付各的哈，这里的AA是其作者的名字的缩写：**A**rne **A**ndersson。

**AA树**，是指红黑树中所有的红色子节点必须只能是右节点，左子节点一律不允许是红色子节点，所以，在AA树中，红色子节点只能是下面这一种形态：

![5](../sources\datastructure\1648938-20201012074100141-1409960465.jpg)

也可以理解为严重右倾主义（我这么说会不会被约去喝茶^^）。

> 其实AA树可以看作2-3树的右倾演化而来，而不是2-3-4树，你可以画个图体验一下。

好了，上面就是左倾红黑树、右倾红黑树、AA树的概念，当然，也有可能存在一种红黑树，比如红色子节点只能是左子节点，是不是叫BB树，咱也不知道，还有一种可能是像下面这种红黑树：

![6](../sources\datastructure\1648938-20201012074100502-1390587452.jpg)

上面这颗树，它既有左边的红色子节点，也有右边的红色子节点，其实它也满足红黑树的定义，这种就只是普通（经典）的红黑树了。

既然红黑树有这么多完全不同的形态，我们要如何快速的记住它们呢？

很难，真的很难，所以，我们只需要记住一种形态就可以了，比如左倾红黑树，其它的形态都是一样的道理，完全不用强形记忆。

因此，下面的内容，我将全部以**左倾红黑树**来讲解，跟经典的红黑树讲法会有点出入，且跟你以前看到的所有文章都不一样，请不要纠结。

# 有趣的插入元素

首先，让我们约定一件事：**插入的节点必须为红色，但如果是根节点，就把它涂成黑色。**

有了这个约定之后，我们使用一步一图的方式来慢慢拆解红黑树（左倾，下同）插入元素的过程。

1. 插入第一个元素F

   第一个元素肯定是根节点，直接涂成黑色：

   ![7](../sources\datastructure\1648938-20201012074100868-1107633557.jpg)

2. 插入第二个元素

   这里分两种情况：比F小，比F大。

   （1）假设插入的元素为D，那么，它比F小，所以会成为F的左子节点：

   ![8](../sources\datastructure\1648938-20201012074101514-926299855.jpg)

   此时，D为红色左子节点，所以，不需要再平衡。

   （2）假设插入的元素为K，那么，它比F大，所以会成为F的右子节点：

   ![9](../sources\datastructure\1648938-20201012074101893-709984556.jpg)

   此时，K为红色右子节点，不符合左倾红黑树的规则，所以，需要再平衡，那么，要如何再平衡呢？

   让我们回归红黑树的本质——2-3-4树，上面包含F和K两个元素的红黑树换成2-3-4树就变成了：

   ![10](../sources\datastructure\1648938-20201012074102299-1910266716.jpg)

   再把这个2-3-4树转换成左倾红黑树就变成了：

   ![11](../sources\datastructure\1648938-20201012074102710-557433298.jpg)

   让我们画一张对比图来看看：

   ![12](../sources\datastructure\1648938-20201012074103090-679457447.jpg)

   所以，你看，结合2-3-4树来理解红黑树是不是就特别简单了，对于2-3-4树就是一个普通的3节点，而对于红黑树相当于插入一个右子节点，再做一次左旋变色即可。

3. 插入第三个元素

   我们以上述的`F K`两个元素的红黑树为例，在这个基础上再增加一个元素，这里可能有三种情况，我们一一来分析：

   （1）假设插入的元素为D，它比F小，所以会成为F的左子节点：

   ![13](../sources\datastructure\1648938-20201012074103518-370008778.jpg)

   此时，显然不符合红黑树的定义了，所以，需要再平衡，那么如何平衡呢？来，上图：

   ![14](../sources\datastructure\1648938-20201012074103871-20160489.jpg)

   插入元素D，对于2-3-4树就是形成一个4节点，而对于红黑树树需要经过右旋再变色的过程。

   （2）假设插入的元素为G，它比F大，比K小，所以会成为F的右子节点：

   ![15](../sources\datastructure\1648938-20201012074104286-1750787929.jpg)

   显然，它也不符合红黑树的定义，所以，也需要再平衡：

   ![16](../sources\datastructure\1648938-20201012074104671-1168664441.jpg)

   插入元素G，对于2-3-4树，只是形成一个普通的4节点，而对于红黑树，需要先以F左旋，变成与情况（1）相同的状态，再以G右旋，然后变色，最终再平衡成红黑树。

   （3）假设插入的元素为N，它比K大，所以会成为K的右子节点：

   ![17](../sources\datastructure\1648938-20201012074105126-759235621.jpg)

   此时，正好符合红黑树的定义，不需要再平衡了，但是，我们同样画一张图对比看下：

   ![18](../sources\datastructure\1648938-20201012074105453-51402742.jpg)

   好了，通过上面的分析，连续插入三个元素，可以看到，对于2-3-4，都是形成一个4节点，而对于红黑树，最终都变成了下面这个样子：

   ![19](../sources\datastructure\1648938-20201012074105900-628414941.jpg)

   所以，我们再插入第四个元素看看。

4. 插入第四个元素

   我们以`F K N`这颗红黑树为例，插入第四个元素，可能会出现四种情况，也就是分别可能会成为F和N的四个子节点的其中之一，简单点，我们直接上图：

   （1）假设为D，其为F的左子节点

   ![20](../sources\datastructure\1648938-20201012074106365-604742459.jpg)

   （2）假设为G，其为F的右子节点

   ![21](../sources\datastructure\1648938-20201012074106923-293723290.jpg)

   （3）假设为M，其为N的左子节点

   ![22](../sources\datastructure\1648938-20201012074107454-571696230.jpg)

   （4）假设为Q，其为N的右子节点

   ![23](../sources\datastructure\1648938-20201012074107951-1816923486.jpg)

   好了，插入四个元素的各种情况到此结束，可以看到，插入第四个元素时，对于2-3-4树，会形成一个5节点，然后再分裂，而对于红黑树，要经过一系列的左旋、右旋、变色，最终转变成跟2-3-4树对应的形态，是不是很好玩儿^^

5. 插入第五个元素

   画图太累，交给你了~~

# 删除元素

不管是2-3-4树还是左倾红黑树删除元素的过程都要比插入元素复杂得多，我们先来看2-3-4树删除元素的过程。

## 2-3-4树删除元素

为了方便讲解，我构造了一颗下图所示的2-3-4树：

![24](../sources\datastructure\1648938-20201012074108557-1374325103.jpg)

对于2-3-4树，删除3节点或4节点的叶子节点是最简单的，比如`C D`和`P Q R`这两个叶子节点，删除这两个节点中的任意一个元素直接删除即可，4节点删除一个元素后变成3节点，3节点删除一个元素之后变成2节点，并不影响原来树的平衡性，比如，删除C之后的结果如下：

![25](../sources\datastructure\1648938-20201012074108976-986688411.jpg)

但是，删除2节点就不一样了，比如，上图删除`A`、`B`、`F`、`G`、`H`、`J`、`L`、`N`这几个节点，直接删除之后树就不平衡了，所以，需要想一些办法来保证删除L之后树依然是平衡的，怎么办呢？

答案是——偷！

没错，就是偷，从别的地方偷元素过来，把这个空缺补上，就像我们上班划水一样，总要找一些东西把工时补上对不对。

那么，怎么个偷法呢？

总体来说，分成两大类，子节点从父节点偷，父节点从子节点偷，偷着偷着可能还要合并或者迁移元素。

我们来分别看一下删除`A`、`B`、`F`、`G`、`H`、`J`、`L`、`N`这几个节点的过程是如何偷的，以下多图，请慎重！

（1）删除A

![26](../sources\datastructure\1648938-20201012074109399-855631352.jpg)

删除A元素时，先从父节点偷个B过来，此时，B位置空缺了，原来B的位置再从其右子节点偷个C过来，搞定。

（2）删除B

![27](../sources\datastructure\1648938-20201012074109982-1299779715.jpg)

删除B就很简单了，直接从右子节点偷个C过来就搞定了。

（3）删除F

![28](../sources\datastructure\1648938-20201012074110498-2054182837.jpg)

删除F的过程就比较复杂了，总之，始终围绕着一个原则：子节点偷不到就偷父节点的，偷过来的元素之后记得可能会合并或者迁移元素。

合并的规则是要始终保证整颗树的有序性，比如，上面从父节点偷了个I过来，它本身就比H大，所以，H必须放在I的左子节点，而左子节点原来已经有G了，所以，只能把它们俩合并了。

同理，迁移J元素的过程也是一样的，J肯定是要放在K的左边，迁移到I的右子节点正好。

（4）删除G

其实跟删除F时从偷I开始是一样的，就不赘述了。

（5）删除H

与删除F的过程一模一样，不再赘述。

（6）删除J

![29](../sources\datastructure\1648938-20201012074111088-968352833.jpg)

删除J时，从父节点先偷个K过来，此时父节点变成了3节点，所以，直接把M左边的两个元素合并即可。

（7）删除L

![30](../sources\datastructure\1648938-20201012074111658-1215644610.jpg)

删除L的过程与删除J的过程有点像，也是从父节点偷K过来，然后再把M左边的两个元素合并。

（8）删除N

![31](../sources\datastructure\1648938-20201012074112196-1201448372.jpg)

删除N时，从父节点偷个O过来，父节点再从其右子节点偷个P过来，偷个屁，偷个屁呀~~

好了，到此为止，2-3-4树删除元素的过程全解析完毕了，我这个示例中几乎包含了所有的场景，请多画图仔细体会，虽然画得想吐血了。

## 左倾红黑树删除元素

> 注：红黑树的删除稍微有点小复杂，如果强型跟2-3-4挂钩会变得更复杂，所以，下面的内容不完全跟2-3-4树挂钩。

首先，我想问一个问题：一颗二叉查找树删除元素之后如何还能保证它还是二叉查找树呢？

![32](../sources\datastructure\1648938-20201012074112793-1560995891.jpg)

如果是叶子节点，删了也就删了，不影响，但如果是非叶子节点呢？比如，删除M这个元素。

其实，有两种方法：一种是找到M的前置节点并拿到M的位置，一种是找到M的后继节点并拿到M的位置。

什么是前置节点？什么是后继节点呢？好像二叉树里面只听说过父节点、子节点？

我们知道二叉查找树本质上是有序的，这个有序性指的是元素的自然顺序（还有一种有序性是插入顺序）。

所以，你把这颗二叉树中的所有元素排个序（或者中序遍历一下），在M前面的那个节点就是前置节点，在M后面的那个节点就是后继节点。

还有一种更形象的方法，M这个节点左子树中最大的元素就是M的前置节点，M节点右子树中最小的元素就是M的后继节点。

所以，删除M后，把L或者N移到M的位置就可以了，此时，就能保证二叉查找树依然是二叉查找树。

![33](../sources\datastructure\1648938-20201012074113397-665036012.jpg)

![34](../sources\datastructure\1648938-20201012074113821-1878206614.jpg)

不过，大家好像都喜欢移后继节点，即右子树中最小的节点你如果看源码的话，会看到一个单词叫作`successor`，就是后继节点的意思。

好了，关于二叉查找树删除元素我们就讲这么多，还是回到红黑树删除元素的过程。

为了方便讲解，我构造了下面这么一颗红黑树：

![35](../sources\datastructure\1648938-20201012074114201-1163612186.jpg)

我们先来看一种最简单的情况，如果删除的是红色的叶子节点，比如，上图中的C、P、R这三个元素，如果它的父节点只有它这么一个子节点，直接删之，啥也不用管，比如C，如果它的父节点有两个子节点，那么会分成两种情况，一种是删除的右子节点，则直接删，比如R，另一种是删除的左子节点，那就做一次简单的左旋即可，比如P。

> 我们这里讲的是左倾红黑树，如果是经典的红黑树，则删除红色叶子节点不需要旋转。

OK，我们再来看第二种情况，如果删除的是黑色的叶子节点呢？

我们知道，黑色节点删除之后，肯定不符合红黑树定义了，所以，肯定要进行再平衡的过程。

如果按照经典红黑树的说法，要看它的兄弟节点的颜色，有可能还要看它兄弟节点的子节点的颜色，情况大概有三四种，根本不可能记得住，我这里介绍一种更牛逼的方法，保证你看一遍就能记住。

我们以删除F节点为例，我先给出图示，下面再描述详细步骤：

![36](../sources\datastructure\1648938-20201012074114620-1387073484.jpg)

这种方法非常简单，F是黑色节点没错，那就想办法把它变成红色节点，怎么变呢？

那就得从它的上层节点动手，上层节点的红色其实是可以向下传递的，传递之后，整颗树其实还是红黑树，并不会打破原来红黑树的平衡，直到F变成红色的叶子节点，再一举把它删除，就很简单了。

这种方法相比于经典红黑树的方法，理解起来就容易得多了。

我们再举个删除L的例子，直接上图：

![37](../sources\datastructure\1648938-20201012074115418-1714249339.jpg)

好了，上面说的都是删除叶子节点，那么，如果删除的是非叶子节点呢，比如删除E。

![38](../sources\datastructure\1648938-20201012074116033-313277404.jpg)

根据二叉查找树的特性，那么，我们会找到E的后继节点F，然后，把它移到E的位置，但是，此时，不符合红黑树的定义了，所以，你可以发现，其实，删除E相当于间接地删除F原来所在的节点位置，因此，又转化成了上面的删除叶子节点。

过程很简单，最后的结果与删除F的结果基本相同，只是原来E所在位置的元素变成了F，我就不画图了。

你可以想想删除M的过程~

总算讲完了，能看到这里的同学不容易，可能已经超出了一顿早餐的时间，我很抱歉！

# 后记

本节，我们从红黑树的本质，即2-3-4树出发，彻底掌握了一种不用死记硬背的方法来理解红黑树，你Get到了吗？欢迎留言评论。

有些同学看到这里，可能又说了：Talk is cheap, show me the code！